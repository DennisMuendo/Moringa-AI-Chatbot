{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "153c69f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T08:55:18.895029Z",
     "iopub.status.busy": "2024-01-24T08:55:18.894624Z",
     "iopub.status.idle": "2024-01-24T08:55:24.761995Z",
     "shell.execute_reply": "2024-01-24T08:55:24.758020Z",
     "shell.execute_reply.started": "2024-01-24T08:55:18.894960Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rouge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordNetLemmatizer\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranslate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleu_score\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m corpus_bleu\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrouge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Rouge\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rouge'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import re \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7f227e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.765951Z",
     "iopub.status.idle": "2024-01-24T08:55:24.767869Z",
     "shell.execute_reply": "2024-01-24T08:55:24.767595Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.767561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609bba95",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.768878Z",
     "iopub.status.idle": "2024-01-24T08:55:24.770524Z",
     "shell.execute_reply": "2024-01-24T08:55:24.770326Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.770302Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "with open('../Final_Intents.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a65a4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.773309Z",
     "iopub.status.idle": "2024-01-24T08:55:24.773927Z",
     "shell.execute_reply": "2024-01-24T08:55:24.773736Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.773714Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to pair each question with its corresponding response\n",
    "def pair_questions_responses(data):\n",
    "    paired_data = []\n",
    "    for item in data:\n",
    "        tag = item.get('tag', 'Unknown')\n",
    "        questions = item.get('questions', [])\n",
    "        responses = item.get('responses', [])\n",
    "\n",
    "        for question, response in zip(questions, responses):\n",
    "            paired_data.append({'tag': tag, 'question': question, 'response': response})\n",
    "\n",
    "    return paired_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf95b7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.776798Z",
     "iopub.status.idle": "2024-01-24T08:55:24.777620Z",
     "shell.execute_reply": "2024-01-24T08:55:24.777420Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.777398Z"
    }
   },
   "outputs": [],
   "source": [
    "paired_data = pair_questions_responses(data)\n",
    "df = pd.DataFrame(paired_data)\n",
    "df.head ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67334f4c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.780297Z",
     "iopub.status.idle": "2024-01-24T08:55:24.781404Z",
     "shell.execute_reply": "2024-01-24T08:55:24.780982Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.780953Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Data Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)  # Remove special characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply preprocessing to questions and responses\n",
    "df['question'] = df['question'].apply(preprocess_text)\n",
    "df['response'] = df['response'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf5a023",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.783207Z",
     "iopub.status.idle": "2024-01-24T08:55:24.783869Z",
     "shell.execute_reply": "2024-01-24T08:55:24.783665Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.783643Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f68c2d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.785591Z",
     "iopub.status.idle": "2024-01-24T08:55:24.786305Z",
     "shell.execute_reply": "2024-01-24T08:55:24.786105Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.786082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data['question'].tolist() + train_data['response'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda5788",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.789018Z",
     "iopub.status.idle": "2024-01-24T08:55:24.789682Z",
     "shell.execute_reply": "2024-01-24T08:55:24.789488Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.789466Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert texts to sequences\n",
    "train_questions_seq = tokenizer.texts_to_sequences(train_data['question'].tolist())\n",
    "train_responses_seq = tokenizer.texts_to_sequences(train_data['response'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87aabc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.792099Z",
     "iopub.status.idle": "2024-01-24T08:55:24.792767Z",
     "shell.execute_reply": "2024-01-24T08:55:24.792571Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.792549Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the maximum sequence length\n",
    "max_seq_length = max(max(len(seq) for seq in train_questions_seq), max(len(seq) for seq in train_responses_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8314670c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.795337Z",
     "iopub.status.idle": "2024-01-24T08:55:24.796003Z",
     "shell.execute_reply": "2024-01-24T08:55:24.795805Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.795783Z"
    }
   },
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "train_questions_padded = pad_sequences(train_questions_seq, maxlen=max_seq_length, padding='post')\n",
    "train_responses_padded = pad_sequences(train_responses_seq, maxlen=max_seq_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a762cff",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.797489Z",
     "iopub.status.idle": "2024-01-24T08:55:24.799116Z",
     "shell.execute_reply": "2024-01-24T08:55:24.798857Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.798829Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preparing test data\n",
    "test_questions_seq = tokenizer.texts_to_sequences(test_data['question'].tolist())\n",
    "test_responses_seq = tokenizer.texts_to_sequences(test_data['response'].tolist())\n",
    "test_questions_padded = pad_sequences(test_questions_seq, maxlen=max_seq_length, padding='post')\n",
    "test_responses_padded = pad_sequences(test_responses_seq, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43050b3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.800316Z",
     "iopub.status.idle": "2024-01-24T08:55:24.801010Z",
     "shell.execute_reply": "2024-01-24T08:55:24.800788Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.800764Z"
    }
   },
   "outputs": [],
   "source": [
    "# One-hot encode the responses\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "train_responses_one_hot = np.zeros((len(train_responses_padded), max_seq_length, vocab_size))\n",
    "\n",
    "for i, sequence in enumerate(train_responses_padded):\n",
    "    for j, word_index in enumerate(sequence):\n",
    "        train_responses_one_hot[i, j, word_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb18d72",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.802828Z",
     "iopub.status.idle": "2024-01-24T08:55:24.804318Z",
     "shell.execute_reply": "2024-01-24T08:55:24.804121Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.804099Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "class BahdanauAttention(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a9087",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.807003Z",
     "iopub.status.idle": "2024-01-24T08:55:24.807683Z",
     "shell.execute_reply": "2024-01-24T08:55:24.807483Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.807461Z"
    }
   },
   "outputs": [],
   "source": [
    "# Updated Model Architecture\n",
    "embedding_dim = 128  # Embedding dimensionality\n",
    "latent_dim = 256 \n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_seq_length,))\n",
    "encoder_embedding = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Bahdanau Attention\n",
    "attention_layer = BahdanauAttention(latent_dim)\n",
    "context_vector, attention_weights = attention_layer(state_h, encoder_outputs)\n",
    "\n",
    "# Decoder with attention\n",
    "decoder_inputs = Input(shape=(max_seq_length,))\n",
    "decoder_embedding = Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
    "context_vector_with_time_axis = tf.expand_dims(context_vector, 1)\n",
    "\n",
    "# Broadcast the context vector to have the same shape as the decoder embedding\n",
    "sequence_length = tf.shape(decoder_embedding)[1]\n",
    "context_vector_broadcasted = tf.broadcast_to(context_vector_with_time_axis, [tf.shape(context_vector_with_time_axis)[0], sequence_length, tf.shape(context_vector_with_time_axis)[-1]])\n",
    "decoder_input_combined = tf.concat([context_vector_broadcasted, decoder_embedding], axis=-1)\n",
    "\n",
    "# Continue with the decoder LSTM, etc.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_input_combined, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ea668",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.809116Z",
     "iopub.status.idle": "2024-01-24T08:55:24.810623Z",
     "shell.execute_reply": "2024-01-24T08:55:24.810340Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.810311Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model with Adam optimizer and use categorical_crossentropy as loss\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c824a96",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.812094Z",
     "iopub.status.idle": "2024-01-24T08:55:24.812773Z",
     "shell.execute_reply": "2024-01-24T08:55:24.812560Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.812538Z"
    }
   },
   "outputs": [],
   "source": [
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c098d28",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.815674Z",
     "iopub.status.idle": "2024-01-24T08:55:24.817033Z",
     "shell.execute_reply": "2024-01-24T08:55:24.816142Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.816120Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "history = model.fit([train_questions_padded, train_responses_padded], train_responses_one_hot,\n",
    "                    batch_size=64,\n",
    "                    epochs=20,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ce571",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.819460Z",
     "iopub.status.idle": "2024-01-24T08:55:24.820144Z",
     "shell.execute_reply": "2024-01-24T08:55:24.819938Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.819915Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_responses_one_hot = np.zeros((len(test_responses_padded), max_seq_length, vocab_size))\n",
    "\n",
    "for i, sequence in enumerate(test_responses_padded):\n",
    "    for j, word_index in enumerate(sequence):\n",
    "        test_responses_one_hot[i, j, word_index] = 1\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate([test_questions_padded, test_responses_padded], test_responses_one_hot)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c22389",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-24T08:55:24.821316Z",
     "iopub.status.idle": "2024-01-24T08:55:24.821955Z",
     "shell.execute_reply": "2024-01-24T08:55:24.821762Z",
     "shell.execute_reply.started": "2024-01-24T08:55:24.821741Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss, train_accuracy = model.evaluate([train_questions_padded, train_responses_padded], train_responses_one_hot)\n",
    "print(\"Train Loss:\", train_loss)\n",
    "print(\"Train Accuracy:\", train_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
