{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dennis\\anaconda3\\envs\\learn-env\\lib\\site-packages\\scipy\\__init__.py:173: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.19.0)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "# Natural Language Processing (NLP)\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Text Vectorization and Machine Learning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score, confusion_matrix,\n",
    "    f1_score, precision_score, recall_score,\n",
    "    roc_auc_score, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    ")\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dennis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dennis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dennis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Final_Intents.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pair each question with its corresponding response\n",
    "def pair_questions_responses(data):\n",
    "    paired_data = []\n",
    "    for item in data:\n",
    "        tag = item.get('tag', 'Unknown')\n",
    "        questions = item.get('questions', [])\n",
    "        responses = item.get('responses', [])\n",
    "\n",
    "        for question, response in zip(questions, responses):\n",
    "            paired_data.append({'tag': tag, 'question': question, 'response': response})\n",
    "\n",
    "    return paired_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>What does the data science course at Moringa S...</td>\n",
       "      <td>The data science course at Moringa School cove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Can you provide details about the curriculum a...</td>\n",
       "      <td>The curriculum and modules in the data science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>How long is the data science course, and what ...</td>\n",
       "      <td>The duration of the data science course is fle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Tell me about the practical aspects of the dat...</td>\n",
       "      <td>Practical aspects of the data science learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Are there any prerequisites for enrolling in t...</td>\n",
       "      <td>Prerequisites for enrolling in the data scienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Is there a limit on the number of financial ai...</td>\n",
       "      <td>The teaching model is hands-on and project-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>How does the Soma Education Loan work?</td>\n",
       "      <td>Students will gain insight into cross-platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Are there repayment options for student loans?</td>\n",
       "      <td>Upon completion of the course, students will r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>What support is available for students applyin...</td>\n",
       "      <td>All classes are fully online. Lecture sessions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>What is the Mpesa Mini Apps &amp; API Development ...</td>\n",
       "      <td>The minimum specifications for your machine ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               tag                                           question  \\\n",
       "0     Data Science  What does the data science course at Moringa S...   \n",
       "1     Data Science  Can you provide details about the curriculum a...   \n",
       "2     Data Science  How long is the data science course, and what ...   \n",
       "3     Data Science  Tell me about the practical aspects of the dat...   \n",
       "4     Data Science  Are there any prerequisites for enrolling in t...   \n",
       "..             ...                                                ...   \n",
       "510  Miscellaneous  Is there a limit on the number of financial ai...   \n",
       "511  Miscellaneous             How does the Soma Education Loan work?   \n",
       "512  Miscellaneous     Are there repayment options for student loans?   \n",
       "513  Miscellaneous  What support is available for students applyin...   \n",
       "514  Miscellaneous  What is the Mpesa Mini Apps & API Development ...   \n",
       "\n",
       "                                              response  \n",
       "0    The data science course at Moringa School cove...  \n",
       "1    The curriculum and modules in the data science...  \n",
       "2    The duration of the data science course is fle...  \n",
       "3    Practical aspects of the data science learning...  \n",
       "4    Prerequisites for enrolling in the data scienc...  \n",
       "..                                                 ...  \n",
       "510  The teaching model is hands-on and project-bas...  \n",
       "511  Students will gain insight into cross-platform...  \n",
       "512  Upon completion of the course, students will r...  \n",
       "513  All classes are fully online. Lecture sessions...  \n",
       "514  The minimum specifications for your machine ar...  \n",
       "\n",
       "[515 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the JSON data into a DataFrame\n",
    "paired_data = pair_questions_responses(data)\n",
    "df = pd.DataFrame(paired_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data science</td>\n",
       "      <td>what does the data science course at moringa s...</td>\n",
       "      <td>the data science course at moringa school cove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data science</td>\n",
       "      <td>can you provide details about the curriculum a...</td>\n",
       "      <td>the curriculum and modules in the data science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data science</td>\n",
       "      <td>how long is the data science course  and what ...</td>\n",
       "      <td>the duration of the data science course is fle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data science</td>\n",
       "      <td>tell me about the practical aspects of the dat...</td>\n",
       "      <td>practical aspects of the data science learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data science</td>\n",
       "      <td>are there any prerequisites for enrolling in t...</td>\n",
       "      <td>prerequisites for enrolling in the data scienc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tag                                           question  \\\n",
       "0  data science  what does the data science course at moringa s...   \n",
       "1  data science  can you provide details about the curriculum a...   \n",
       "2  data science  how long is the data science course  and what ...   \n",
       "3  data science  tell me about the practical aspects of the dat...   \n",
       "4  data science  are there any prerequisites for enrolling in t...   \n",
       "\n",
       "                                            response  \n",
       "0  the data science course at moringa school cove...  \n",
       "1  the curriculum and modules in the data science...  \n",
       "2  the duration of the data science course is fle...  \n",
       "3  practical aspects of the data science learning...  \n",
       "4  prerequisites for enrolling in the data scienc...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Cleaning\n",
    "# Remove any unnecessary characters, symbols, or special characters.\n",
    "# Convert text to lowercase to ensure uniformity.\n",
    "df['question'] = df['question'].str.lower().replace('[^a-zA-Z0-9]', ' ', regex=True)\n",
    "df['response'] = df['response'].str.lower().replace('[^a-zA-Z0-9]', ' ', regex=True)\n",
    "df['tag'] = df['tag'].str.lower().replace('[^a-zA-Z0-9]', ' ', regex=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QnAs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>while maintaining a structured approach, we pr...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>while there may not be strict prerequisites, a...</td>\n",
       "      <td>Cloud Computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>are there any discount available for early pay...</td>\n",
       "      <td>DevOps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>applicant must be above 18 year of age to enro...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>what document do i need to apply for the course?</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  QnAs             tags\n",
       "347  while maintaining a structured approach, we pr...     Data Science\n",
       "730  while there may not be strict prerequisites, a...  Cloud Computing\n",
       "445  are there any discount available for early pay...           DevOps\n",
       "250  applicant must be above 18 year of age to enro...     Data Science\n",
       "43    what document do i need to apply for the course?     Data Science"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "QnAs = []\n",
    "tags = []\n",
    "\n",
    "for intent in data:\n",
    "    for question in intent[\"questions\"]:\n",
    "        QnAs.append(question)\n",
    "        tags.append(intent['tag'])\n",
    "    for response in intent[\"responses\"]:\n",
    "        QnAs.append(response)\n",
    "        tags.append(intent['tag'])\n",
    "# Preprocess the text by lemmatizing and lowercasing\n",
    "\n",
    "qna_df = pd.DataFrame({\"QnAs\": QnAs, \"tags\": tags})\n",
    "\n",
    "qna_df[\"QnAs\"] = qna_df[\"QnAs\"].apply(lambda x: ' '.join([lemmatizer.lemmatize(word.lower()) for word in x.split()]))\n",
    "\n",
    "qna_df = qna_df.reindex(np.random.permutation(qna_df.index))\n",
    "#qna_df = preprocess_qnas(qna_df)\n",
    "qna_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QnAs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>[while, maintaining, a, structured, approach, ...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>[while, there, may, not, be, strict, prerequis...</td>\n",
       "      <td>Cloud Computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>[are, there, any, discount, available, for, ea...</td>\n",
       "      <td>DevOps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>[applicant, must, be, above, 18, year, of, age...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[what, document, do, i, need, to, apply, for, ...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  QnAs             tags\n",
       "347  [while, maintaining, a, structured, approach, ...     Data Science\n",
       "730  [while, there, may, not, be, strict, prerequis...  Cloud Computing\n",
       "445  [are, there, any, discount, available, for, ea...           DevOps\n",
       "250  [applicant, must, be, above, 18, year, of, age...     Data Science\n",
       "43   [what, document, do, i, need, to, apply, for, ...     Data Science"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the 'QnAs' column\n",
    "qna_df[\"QnAs\"] = qna_df[\"QnAs\"].apply(word_tokenize)\n",
    "\n",
    "# Display the DataFrame with tokenized text\n",
    "qna_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QnAs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>[maintaining, structured, approach, ,, provide...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>[may, strict, prerequisites, ,, basic, underst...</td>\n",
       "      <td>Cloud Computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>[discount, available, early, payment, tuition,...</td>\n",
       "      <td>DevOps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>[applicant, must, 18, year, age, enroll, data,...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[document, need, apply, course, ?]</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>[tell, software, engineering, mobile, track, m...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>[certification, well-regarded, industry, ,, re...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>[find, testimonial, individual, completed, spe...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>[specific, role, devops, professionals, ?]</td>\n",
       "      <td>DevOps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>[provide, networking, opportunity, industry, e...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  QnAs             tags\n",
       "347  [maintaining, structured, approach, ,, provide...     Data Science\n",
       "730  [may, strict, prerequisites, ,, basic, underst...  Cloud Computing\n",
       "445  [discount, available, early, payment, tuition,...           DevOps\n",
       "250  [applicant, must, 18, year, age, enroll, data,...     Data Science\n",
       "43                  [document, need, apply, course, ?]     Data Science\n",
       "..                                                 ...              ...\n",
       "911  [tell, software, engineering, mobile, track, m...    Miscellaneous\n",
       "365  [certification, well-regarded, industry, ,, re...     Data Science\n",
       "933  [find, testimonial, individual, completed, spe...    Miscellaneous\n",
       "435         [specific, role, devops, professionals, ?]           DevOps\n",
       "396  [provide, networking, opportunity, industry, e...     Data Science\n",
       "\n",
       "[1040 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords from the 'QnAs_tokens' column\n",
    "qna_df[\"QnAs\"] = qna_df[\"QnAs\"].apply(lambda tokens: [word for word in tokens if word.lower() not in stop_words])\n",
    "\n",
    "# Display the DataFrame with removed stopwords\n",
    "qna_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization using TF-IDF for QnAs\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(\n",
    "    qna_df[\"QnAs\"].apply(lambda row: ' '.join(row))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8317307692307693\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "     Cloud Computing       0.93      1.00      0.97        14\n",
      "            Contacts       0.25      0.50      0.33         2\n",
      "       Cybersecurity       0.86      0.92      0.89        13\n",
      "        Data Science       0.87      0.84      0.86        90\n",
      "              DevOps       1.00      0.56      0.71         9\n",
      "          Enrollment       0.86      0.92      0.89        13\n",
      "       Miscellaneous       0.72      0.64      0.68        28\n",
      "  Mobile Development       0.91      0.91      0.91        11\n",
      "Software Engineering       0.76      0.92      0.83        24\n",
      "               UI/UX       0.75      0.75      0.75         4\n",
      "\n",
      "            accuracy                           0.83       208\n",
      "           macro avg       0.79      0.80      0.78       208\n",
      "        weighted avg       0.84      0.83      0.83       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, qna_df['tags'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a model \n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'objective': 'multi:softprob',\n",
       " 'max_depth': None,\n",
       " 'learning_rate': None,\n",
       " 'verbosity': None,\n",
       " 'booster': None,\n",
       " 'tree_method': None,\n",
       " 'gamma': None,\n",
       " 'min_child_weight': None,\n",
       " 'max_delta_step': None,\n",
       " 'subsample': None,\n",
       " 'colsample_bytree': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'base_score': None,\n",
       " 'missing': nan,\n",
       " 'num_parallel_tree': None,\n",
       " 'kwargs': {},\n",
       " 'random_state': None,\n",
       " 'n_jobs': None,\n",
       " 'monotone_constraints': None,\n",
       " 'interaction_constraints': None,\n",
       " 'importance_type': 'gain',\n",
       " 'gpu_id': None,\n",
       " 'validate_parameters': None,\n",
       " 'classes_': array(['Cloud Computing', 'Contacts', 'Cybersecurity', 'Data Science',\n",
       "        'DevOps', 'Enrollment', 'Miscellaneous', 'Mobile Development',\n",
       "        'Software Engineering', 'UI/UX'], dtype=object),\n",
       " 'n_classes_': 10,\n",
       " '_le': XGBoostLabelEncoder(),\n",
       " '_features_count': 1637,\n",
       " 'n_features_in_': 1637,\n",
       " '_Booster': <xgboost.core.Booster at 0x1ec4aae3f40>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200}\n",
      "Best Accuracy for XGBoost: 0.829326888391891\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_xgb = GridSearchCV(xgb_model, param_grid=param_grid_xgb, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding accuracy\n",
    "print(\"Best Parameters for XGBoost:\", grid_search_xgb.best_params_)\n",
    "print(\"Best Accuracy for XGBoost:\", grid_search_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTINOMIAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a multinomial model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5865384615384616\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "     Cloud Computing       1.00      0.29      0.44        14\n",
      "            Contacts       0.00      0.00      0.00         2\n",
      "       Cybersecurity       0.00      0.00      0.00        13\n",
      "        Data Science       0.53      0.99      0.69        90\n",
      "              DevOps       1.00      0.33      0.50         9\n",
      "          Enrollment       0.90      0.69      0.78        13\n",
      "       Miscellaneous       0.78      0.25      0.38        28\n",
      "  Mobile Development       1.00      0.09      0.17        11\n",
      "Software Engineering       0.64      0.38      0.47        24\n",
      "               UI/UX       0.00      0.00      0.00         4\n",
      "\n",
      "            accuracy                           0.59       208\n",
      "           macro avg       0.59      0.30      0.34       208\n",
      "        weighted avg       0.63      0.59      0.51       208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dennis\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning for Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Multinomial Naive Bayes: {'alpha': 0.1}\n",
      "Best Accuracy for Multinomial Naive Bayes: 0.7535747781545343\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_nb = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0]\n",
    "}\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_nb = GridSearchCV(nb_model, param_grid=param_grid_nb, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_nb.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding accuracy\n",
    "print(\"Best Parameters for Multinomial Naive Bayes:\", grid_search_nb.best_params_)\n",
    "print(\"Best Accuracy for Multinomial Naive Bayes:\", grid_search_nb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, qna_df['tags'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Accuracy: 0.8461538461538461\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "     Cloud Computing       1.00      1.00      1.00        14\n",
      "            Contacts       0.50      0.50      0.50         2\n",
      "       Cybersecurity       1.00      0.77      0.87        13\n",
      "        Data Science       0.85      0.93      0.89        90\n",
      "              DevOps       1.00      0.67      0.80         9\n",
      "          Enrollment       0.92      0.92      0.92        13\n",
      "       Miscellaneous       0.73      0.68      0.70        28\n",
      "  Mobile Development       0.71      0.91      0.80        11\n",
      "Software Engineering       0.84      0.67      0.74        24\n",
      "               UI/UX       0.80      1.00      0.89         4\n",
      "\n",
      "            accuracy                           0.85       208\n",
      "           macro avg       0.84      0.80      0.81       208\n",
      "        weighted avg       0.85      0.85      0.84       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Model Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Accuracy for Random Forest: 0.842558256980016\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid=param_grid_rf, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding accuracy\n",
    "print(\"Best Parameters for Random Forest:\", grid_search_rf.best_params_)\n",
    "print(\"Best Accuracy for Random Forest:\", grid_search_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(**grid_search_rf.best_params_)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8365384615384616"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "rf_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Accuracy: 0.8557692307692307\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "     Cloud Computing       1.00      1.00      1.00        14\n",
      "            Contacts       1.00      0.50      0.67         2\n",
      "       Cybersecurity       1.00      0.77      0.87        13\n",
      "        Data Science       0.85      0.94      0.89        90\n",
      "              DevOps       1.00      0.67      0.80         9\n",
      "          Enrollment       0.92      0.92      0.92        13\n",
      "       Miscellaneous       0.79      0.68      0.73        28\n",
      "  Mobile Development       0.83      0.91      0.87        11\n",
      "Software Engineering       0.75      0.75      0.75        24\n",
      "               UI/UX       0.75      0.75      0.75         4\n",
      "\n",
      "            accuracy                           0.86       208\n",
      "           macro avg       0.89      0.79      0.83       208\n",
      "        weighted avg       0.86      0.86      0.85       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(min_samples_split=5, n_estimators=200)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Model Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Science']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def clean_text(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = word_tokenize(sentence)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    sentence = [word for word in sentence if word not in stop_words]\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# Test text\n",
    "text = \"How long does cyber security take ?\"\n",
    "\n",
    "# Clean and preprocess the test text\n",
    "prep_text = clean_text(text)\n",
    "\n",
    "# Use the same fitted TfidfVectorizer from your training code\n",
    "vectorized_txt = tfidf_vectorizer.transform([' '.join(prep_text)])\n",
    "\n",
    "# Predict using the trained model\n",
    "pred = model.predict(vectorized_txt)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization using TF-IDF for both 'question' and 'response'\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(\n",
    "    qna_df[\"QnAs\"].apply(lambda row: ' '.join(row))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['How is the curriculum at Moringa School tailored to market-aligned skills in Cloud Computing ?']\n",
    "# Tokenize each string in the list\n",
    "tokenized_text = [nltk.word_tokenize(sentence) for sentence in text]\n",
    "\n",
    "# Flatten the list of lists to get a list of words\n",
    "flattened_text = [word for sentence_tokens in tokenized_text for word in sentence_tokens]\n",
    "\n",
    "text = ' '.join([lemmatizer.lemmatize(word) for word in flattened_text])\n",
    "#text = text.lower().replace('[^a-zA-Z0-9]', ' ')\n",
    "text = ' '.join([word for word in text if word not in stop_words])\n",
    "                            \n",
    "vectorized = tfidf_vectorizer.transform([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Science'], dtype='<U20')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized and Lemmatized Input: ['curriculum', 'moringa', 'school', 'tailored', 'market-aligned', 'skill', 'cloud', 'computing', '?']\n",
      "Predicted Category: ['Data Science']\n"
     ]
    }
   ],
   "source": [
    "# Example for checking tokenized input\n",
    "input_text = 'How is the curriculum at Moringa School tailored to market-aligned skills in Cloud Computing ?'\n",
    "tokenized_input = word_tokenize(input_text.lower())\n",
    "lemmatized_input = [lemmatizer.lemmatize(word) for word in tokenized_input if word not in stop_words]\n",
    "\n",
    "print(\"Tokenized and Lemmatized Input:\", lemmatized_input)\n",
    "\n",
    "# Vectorize the input\n",
    "vectorized_input = tfidf_vectorizer.transform([' '.join(lemmatized_input)])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(vectorized_input)\n",
    "print(\"Predicted Category:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Science']\n"
     ]
    }
   ],
   "source": [
    "# Example input text\n",
    "text = ['How long does cyber security take ?']\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "tokenized_text = [nltk.word_tokenize(sentence) for sentence in text]\n",
    "flattened_text = [word for sentence_tokens in tokenized_text for word in sentence_tokens]\n",
    "processed_text = ' '.join([lemmatizer.lemmatize(word) for word in flattened_text])\n",
    "\n",
    "# Remove stopwords\n",
    "processed_text = ' '.join([word for word in processed_text.split() if word not in stop_words])\n",
    "\n",
    "# Transform using the same TF-IDF vectorizer\n",
    "vectorized_text = tfidf_vectorizer.transform([processed_text])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(vectorized_text)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Probabilities: [[0.07300233 0.00998406 0.04632034 0.533577   0.03112474 0.05381455\n",
      "  0.1375134  0.03749257 0.05902109 0.01814993]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = model.predict_proba(vectorized_input)\n",
    "print(\"Raw Probabilities:\", probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Labels: ['Cloud Computing' 'Contacts' 'Cybersecurity' 'Data Science' 'DevOps'\n",
      " 'Enrollment' 'Miscellaneous' 'Mobile Development' 'Software Engineering'\n",
      " 'UI/UX']\n"
     ]
    }
   ],
   "source": [
    "print(\"Class Labels:\", model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
